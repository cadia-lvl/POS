{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "from pos import evaluate\n",
    "from pos import data\n",
    "EXPERIMENT_DIR=Path(\".\")/\"out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the experiment files\n",
    "Here are some useful functions for gathering experimental data and doing averages across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(experiment_name):\n",
    "    predictions = EXPERIMENT_DIR / experiment_name / \"predictions.tsv\"\n",
    "    return evaluate.analyse_examples(evaluate.flatten_data(data.read_tsv(str(predictions))))\n",
    "\n",
    "def get_dicts(experiment_name):\n",
    "    with (EXPERIMENT_DIR / experiment_name / \"dictionaries.pickle\").open('rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def gather_experiments(experiments):\n",
    "    experiments = { \n",
    "        experiment_name: {\n",
    "            \"examples\": get_examples(experiment_name),\n",
    "            \"dicts\": get_dicts(experiment_name),\n",
    "        } for experiment_name in experiments\n",
    "    }\n",
    "    for experiment_name, experiment in experiments.items():\n",
    "        experiment[\"test_vocab\"] = evaluate.get_vocab(experiment[\"examples\"])\n",
    "        experiment[\"train_vocab\"] = set(experiment[\"dicts\"][\"w_map\"].w2i.keys())\n",
    "        experiment[\"morphlex_vocab\"] = set(experiment[\"dicts\"][\"m_map\"].w2i.keys())\n",
    "        experiment[\"both_vocab\"] = experiment[\"train_vocab\"].union(experiment[\"morphlex_vocab\"])\n",
    "        experiment[\"neither_vocab\"] = experiment[\"test_vocab\"].difference(experiment[\"both_vocab\"])\n",
    "    return experiments\n",
    "\n",
    "def accuracy_filter(experiment, filter_vocab=None):\n",
    "    if filter_vocab is not None:\n",
    "        return evaluate.calculate_accuracy(evaluate.filter_examples(experiment['examples'], experiment[filter_vocab]))\n",
    "    return evaluate.calculate_accuracy(experiment['examples'])\n",
    "\n",
    "def print_errors(experiments):\n",
    "    for experiment_name in experiments:\n",
    "        print(experiment_name)\n",
    "        errors = evaluate.all_errors(experiments[experiment_name][\"examples\"])\n",
    "        pprint(errors.most_common(20))\n",
    "\n",
    "def average_accuracy(experiments, filter_vocab=None):\n",
    "    if filter_vocab is not None:\n",
    "        sum(accuracy_filter(experiment, filter_vocab=filter_vocab\n",
    "            ) for experiment in experiments.values()) / len(experiments)\n",
    "    return sum((evaluate.calculate_accuracy(experiment['examples']) for experiment in experiments.values())) / len(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'out/gold-baseline/01/predictions.tsv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-26bdc3a29604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m fold_experiments = {\n\u001b[1;32m      2\u001b[0m     \"baseline\": gather_experiments(f\"gold-baseline/{i:02}\" \n\u001b[0;32m----> 3\u001b[0;31m         for i in range(1, 10))\n\u001b[0m\u001b[1;32m      4\u001b[0m }\n",
      "\u001b[0;32m<ipython-input-3-5b775801f683>\u001b[0m in \u001b[0;36mgather_experiments\u001b[0;34m(experiments)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;34m\"examples\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;34m\"dicts\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         } for experiment_name in experiments\n\u001b[0m\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5b775801f683>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;34m\"examples\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;34m\"dicts\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         } for experiment_name in experiments\n\u001b[0m\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5b775801f683>\u001b[0m in \u001b[0;36mget_examples\u001b[0;34m(experiment_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXPERIMENT_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mexperiment_name\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"predictions.tsv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyse_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ABLTagger/pos/data.py\u001b[0m in \u001b[0;36mread_tsv\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmodel_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0msent_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0msent_tags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'out/gold-baseline/01/predictions.tsv'"
     ]
    }
   ],
   "source": [
    "fold_experiments = {\n",
    "    \"baseline\": gather_experiments(f\"gold-baseline/{i:02}\" \n",
    "        for i in range(1, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "total=13277,                 train=116,                 morphlex=54068,                 both=54178,                 neither=864\ntotal=12615,                 train=116,                 morphlex=54068,                 both=54178,                 neither=750\ntotal=12551,                 train=114,                 morphlex=54068,                 both=54176,                 neither=811\ntotal=12431,                 train=116,                 morphlex=54068,                 both=54178,                 neither=872\ntotal=12379,                 train=116,                 morphlex=54068,                 both=54178,                 neither=807\ntotal=12626,                 train=114,                 morphlex=54068,                 both=54176,                 neither=830\ntotal=12567,                 train=115,                 morphlex=54068,                 both=54177,                 neither=846\ntotal=12806,                 train=114,                 morphlex=54068,                 both=54176,                 neither=874\ntotal=12694,                 train=116,                 morphlex=54068,                 both=54178,                 neither=844\ntotal=20949,                 train=142,                 morphlex=67062,                 both=67197,                 neither=5997\ntotal=20809,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5885\ntotal=21220,                 train=143,                 morphlex=67062,                 both=67198,                 neither=6082\ntotal=20189,                 train=141,                 morphlex=67062,                 both=67196,                 neither=4722\ntotal=20400,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5158\ntotal=22150,                 train=143,                 morphlex=67062,                 both=67198,                 neither=6157\ntotal=21431,                 train=142,                 morphlex=67062,                 both=67197,                 neither=5924\ntotal=20532,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5150\ntotal=20915,                 train=142,                 morphlex=67062,                 both=67197,                 neither=5240\ntotal=20766,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5741\nTotal acc=0.9522, known acc=0.9522,     unk acc=0.9522\nTotal acc=0.9406, known acc=0.9406,     unk acc=0.9406\n"
    }
   ],
   "source": [
    "for fold_experiment in fold_experiments:\n",
    "        for experiment in fold_experiment.values():\n",
    "            print(f\"total={len(experiment['test_vocab'])}, \\\n",
    "                train={len(experiment['train_vocab'])}, \\\n",
    "                morphlex={len(experiment['morphlex_vocab'])}, \\\n",
    "                both={len(experiment['both_vocab'])}, \\\n",
    "                neither={len(experiment['neither_vocab'])}\")\n",
    "for fold_experiment in fold_experiments:\n",
    "    print(f\"Total acc={average_accuracy(fold_experiment):.4f}, known acc={average_accuracy(fold_experiment, filter_vocab='both_vocab'):.4f}, \\\n",
    "    unk acc={average_accuracy(fold_experiment, filter_vocab='neither_vocab'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual experiments\n",
    "Define individual experiments and do analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"abl-tagger-baseline\"\n",
    "experiment_names = [\n",
    "    baseline,\n",
    "    \"baseline\",\n",
    "]\n",
    "experiments = gather_experiments(experiment_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "total=12324, train=55737, morphlex=54068,         both=58988, neither=385\nTotal acc=0.9224, known acc=0.9273,         unk acc=0.3075\ntotal=12324, train=51824, morphlex=54068,         both=56562, neither=412\nTotal acc=0.9584, known acc=0.9603,         unk acc=0.7832\n"
    }
   ],
   "source": [
    "for experiment in experiments.values():\n",
    "    print(f\"total={len(experiment['test_vocab'])}, \\\n",
    "                train={len(experiment['train_vocab'])}, \\\n",
    "                morphlex={len(experiment['morphlex_vocab'])}, \\\n",
    "                both={len(experiment['both_vocab'])}, \\\n",
    "                neither={len(experiment['neither_vocab'])}\")\n",
    "    print(f\"Total acc={accuracy_filter(experiment):.4f}, known acc={accuracy_filter(experiment, filter_vocab='both_vocab'):.4f}, \\\n",
    "        unk acc={accuracy_filter(experiment, filter_vocab='neither_vocab'):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors\n",
    "Proposed tag -> gold tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_errors(experiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_diff(baseline, compare_to):\n",
    "    result = {}\n",
    "    for key, value in baseline.items():\n",
    "        if key not in compare_to:\n",
    "            result[key] = basline[key]\n",
    "            continue\n",
    "        diff = baseline[key] - compare_to[key]\n",
    "        if diff != 0:\n",
    "            result[key] = diff\n",
    "    return result\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c_1 = Counter((1, 1, 2))\n",
    "c_2 = Counter((1, 1, 3))\n",
    "print(c_1 - c_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = \"sgd+morph_lex-freeze+wemb-pretrained-300-reduced-lr\"\n",
    "baseline_errors = evaluate.all_errors(experiments[baseline][\"examples\"])\n",
    "for experiment_name in experiments:\n",
    "    if experiment_name == baseline:\n",
    "        continue\n",
    "    print(f\"{experiment_name}: First, in basline not in {experiment_name}, then in {experiment_name} not in basline.\")\n",
    "    pprint((evaluate.all_errors(experiments[baseline][\"examples\"]) - evaluate.all_errors(experiments[experiment_name][\"examples\"])).most_common(20))\n",
    "    pprint((evaluate.all_errors(experiments[experiment_name][\"examples\"]) - evaluate.all_errors(experiments[baseline][\"examples\"])).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitposconda0523c88e767045dc9cfcfe32838715d2",
   "display_name": "Python 3.7.6 64-bit ('pos': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}