{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "from pos import evaluate\n",
    "from pos import data\n",
    "EXPERIMENT_DIR=Path(\".\")/\"out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the experiment files\n",
    "Here are some useful functions for gathering experimental data and doing averages across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(experiment_name):\n",
    "    predictions = EXPERIMENT_DIR / experiment_name / \"predictions.tsv\"\n",
    "    return evaluate.analyse_examples(evaluate.flatten_data(data.read_tsv(str(predictions))))\n",
    "\n",
    "def get_vocab(experiment_name):\n",
    "    with (EXPERIMENT_DIR / experiment_name / \"dictionaries.pickle\").open('rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def gather_experiments(experiments):\n",
    "    experiments = { \n",
    "        experiment_name: {\n",
    "            \"examples\": get_examples(experiment_name),\n",
    "            \"vocabmap\": get_vocab(experiment_name),\n",
    "        } for experiment_name in experiments\n",
    "    }\n",
    "    for experiment_name, experiment in experiments.items():\n",
    "        experiments[experiment_name][\"test_vocab\"] = evaluate.get_vocab(experiments[experiment_name][\"examples\"])\n",
    "        experiments[experiment_name][\"train_vocab\"] = set(experiments[experiment_name][\"vocabmap\"].w_map.w2i.keys())\n",
    "        experiments[experiment_name][\"morphlex_vocab\"] = set(experiments[experiment_name][\"vocabmap\"].m_map.w2i.keys())\n",
    "        experiments[experiment_name][\"both_vocab\"] = experiments[experiment_name][\"train_vocab\"].union(experiments[experiment_name][\"morphlex_vocab\"])\n",
    "        experiments[experiment_name][\"neither_vocab\"] = experiments[experiment_name][\"test_vocab\"].difference(experiments[experiment_name][\"both_vocab\"])\n",
    "    return experiments\n",
    "\n",
    "def accuracy_filter(experiment, filter_vocab=None):\n",
    "    if filter_vocab is not None:\n",
    "        return evaluate.calculate_accuracy(evaluate.filter_examples(experiment['examples'], experiment[filter_vocab]))\n",
    "    return evaluate.calculate_accuracy(experiment['examples'])\n",
    "\n",
    "def print_errors(experiments):\n",
    "    for experiment_name in experiments:\n",
    "        print(experiment_name)\n",
    "        errors = evaluate.all_errors(experiments[experiment_name][\"examples\"])\n",
    "        pprint(errors.most_common(20))\n",
    "\n",
    "def average_accuracy(experiments, filter_vocab=None):\n",
    "    if filter_vocab is not None:\n",
    "        sum(accuracy_filter(experiment, filter_vocab=filter_vocab\n",
    "            ) for experiment in experiments.values()) / len(experiments)\n",
    "    return sum((evaluate.calculate_accuracy(experiment['examples']) for experiment in experiments.values())) / len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "VocabMap(w2i={'<pad>': 0, '<unk>': 1, 'ý': 2, '(': 3, '*': 4, '+': 5, 'T': 6, 'd': 7, 'v': 8, '}': 9, 'ú': 10, 'Y': 11, 'l': 12, 'L': 13, '!': 14, '[': 15, 'M': 16, 'í': 17, 'Z': 18, 'x': 19, 'k': 20, '3': 21, '½': 22, ',': 23, 'f': 24, 'Á': 25, 'h': 26, 'E': 27, 'Ó': 28, 'K': 29, '7': 30, '«': 31, 'w': 32, '-': 33, 'm': 34, 'U': 35, 'G': 36, 'B': 37, '{': 38, 'I': 39, '5': 40, ';': 41, 'é': 42, 'n': 43, ':': 44, '±': 45, 'V': 46, 'Í': 47, '9': 48, '»': 49, '°': 50, 'o': 51, '%': 52, '$': 53, 'X': 54, \"'\": 55, 'ä': 56, 't': 57, 'S': 58, 'ü': 59, 'Æ': 60, 'ð': 61, '&': 62, 'p': 63, 'Ö': 64, 'a': 65, 'c': 66, '_': 67, 'Ú': 68, 'N': 69, '.': 70, '=': 71, '÷': 72, '6': 73, '4': 74, 'e': 75, 's': 76, 'Þ': 77, 'ë': 78, 'P': 79, 'i': 80, 'J': 81, 'R': 82, 'F': 83, 'u': 84, 'A': 85, 'H': 86, '1': 87, 'j': 88, 'r': 89, 'á': 90, 'è': 91, 'W': 92, '2': 93, 'æ': 94, '0': 95, 'D': 96, 'ó': 97, 'z': 98, 'g': 99, 'y': 100, 'q': 101, 'b': 102, '?': 103, '\\\\': 104, '^': 105, 'à': 106, 'ö': 107, 'C': 108, 'þ': 109, '8': 110, ']': 111, '/': 112, 'å': 113, 'O': 114, ')': 115}, i2w={0: '<pad>', 1: '<unk>', 2: 'ý', 3: '(', 4: '*', 5: '+', 6: 'T', 7: 'd', 8: 'v', 9: '}', 10: 'ú', 11: 'Y', 12: 'l', 13: 'L', 14: '!', 15: '[', 16: 'M', 17: 'í', 18: 'Z', 19: 'x', 20: 'k', 21: '3', 22: '½', 23: ',', 24: 'f', 25: 'Á', 26: 'h', 27: 'E', 28: 'Ó', 29: 'K', 30: '7', 31: '«', 32: 'w', 33: '-', 34: 'm', 35: 'U', 36: 'G', 37: 'B', 38: '{', 39: 'I', 40: '5', 41: ';', 42: 'é', 43: 'n', 44: ':', 45: '±', 46: 'V', 47: 'Í', 48: '9', 49: '»', 50: '°', 51: 'o', 52: '%', 53: '$', 54: 'X', 55: \"'\", 56: 'ä', 57: 't', 58: 'S', 59: 'ü', 60: 'Æ', 61: 'ð', 62: '&', 63: 'p', 64: 'Ö', 65: 'a', 66: 'c', 67: '_', 68: 'Ú', 69: 'N', 70: '.', 71: '=', 72: '÷', 73: '6', 74: '4', 75: 'e', 76: 's', 77: 'Þ', 78: 'ë', 79: 'P', 80: 'i', 81: 'J', 82: 'R', 83: 'F', 84: 'u', 85: 'A', 86: 'H', 87: '1', 88: 'j', 89: 'r', 90: 'á', 91: 'è', 92: 'W', 93: '2', 94: 'æ', 95: '0', 96: 'D', 97: 'ó', 98: 'z', 99: 'g', 100: 'y', 101: 'q', 102: 'b', 103: '?', 104: '\\\\', 105: '^', 106: 'à', 107: 'ö', 108: 'C', 109: 'þ', 110: '8', 111: ']', 112: '/', 113: 'å', 114: 'O', 115: ')'})\n"
    }
   ],
   "source": [
    "pprint(fold_experiments[0]['ifd-abl-tagger-baseline/01']['vocabmap'].w_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_experiments = [\n",
    "    gather_experiments(f\"ifd-abl-tagger-baseline/{i:02}\" for i in range(1, 10)),\n",
    "    gather_experiments(f\"gold-abl-tagger-baseline/{i:02}\" for i in range(1, 11)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "total=13277,                 train=116,                 morphlex=54068,                 both=54178,                 neither=864\ntotal=12615,                 train=116,                 morphlex=54068,                 both=54178,                 neither=750\ntotal=12551,                 train=114,                 morphlex=54068,                 both=54176,                 neither=811\ntotal=12431,                 train=116,                 morphlex=54068,                 both=54178,                 neither=872\ntotal=12379,                 train=116,                 morphlex=54068,                 both=54178,                 neither=807\ntotal=12626,                 train=114,                 morphlex=54068,                 both=54176,                 neither=830\ntotal=12567,                 train=115,                 morphlex=54068,                 both=54177,                 neither=846\ntotal=12806,                 train=114,                 morphlex=54068,                 both=54176,                 neither=874\ntotal=12694,                 train=116,                 morphlex=54068,                 both=54178,                 neither=844\ntotal=20949,                 train=142,                 morphlex=67062,                 both=67197,                 neither=5997\ntotal=20809,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5885\ntotal=21220,                 train=143,                 morphlex=67062,                 both=67198,                 neither=6082\ntotal=20189,                 train=141,                 morphlex=67062,                 both=67196,                 neither=4722\ntotal=20400,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5158\ntotal=22150,                 train=143,                 morphlex=67062,                 both=67198,                 neither=6157\ntotal=21431,                 train=142,                 morphlex=67062,                 both=67197,                 neither=5924\ntotal=20532,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5150\ntotal=20915,                 train=142,                 morphlex=67062,                 both=67197,                 neither=5240\ntotal=20766,                 train=143,                 morphlex=67062,                 both=67198,                 neither=5741\nTotal acc=0.9522, known acc=0.9522,     unk acc=0.9522\nTotal acc=0.9406, known acc=0.9406,     unk acc=0.9406\n"
    }
   ],
   "source": [
    "for fold_experiment in fold_experiments:\n",
    "        for experiment in fold_experiment.values():\n",
    "            print(f\"total={len(experiment['test_vocab'])}, \\\n",
    "                train={len(experiment['train_vocab'])}, \\\n",
    "                morphlex={len(experiment['morphlex_vocab'])}, \\\n",
    "                both={len(experiment['both_vocab'])}, \\\n",
    "                neither={len(experiment['neither_vocab'])}\")\n",
    "for fold_experiment in fold_experiments:\n",
    "    print(f\"Total acc={average_accuracy(fold_experiment):.4f}, known acc={average_accuracy(fold_experiment, filter_vocab='both_vocab'):.4f}, \\\n",
    "    unk acc={average_accuracy(fold_experiment, filter_vocab='neither_vocab'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual experiments\n",
    "Define individual experiments and do analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"abl-tagger-baseline\"\n",
    "experiment_names = [\n",
    "    baseline,\n",
    "    \"baseline\",\n",
    "]\n",
    "experiments = gather_experiments(experiment_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "total=12324, train=55737, morphlex=54068,         both=58988, neither=385\nTotal acc=0.9224, known acc=0.9273,         unk acc=0.3075\ntotal=12324, train=51824, morphlex=54068,         both=56562, neither=412\nTotal acc=0.9584, known acc=0.9603,         unk acc=0.7832\n"
    }
   ],
   "source": [
    "for experiment in experiments.values():\n",
    "    print(f\"total={len(experiment['test_vocab'])}, \\\n",
    "                train={len(experiment['train_vocab'])}, \\\n",
    "                morphlex={len(experiment['morphlex_vocab'])}, \\\n",
    "                both={len(experiment['both_vocab'])}, \\\n",
    "                neither={len(experiment['neither_vocab'])}\")\n",
    "    print(f\"Total acc={accuracy_filter(experiment):.4f}, known acc={accuracy_filter(experiment, filter_vocab='both_vocab'):.4f}, \\\n",
    "        unk acc={accuracy_filter(experiment, filter_vocab='neither_vocab'):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors\n",
    "Proposed tag -> gold tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_errors(experiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_diff(baseline, compare_to):\n",
    "    result = {}\n",
    "    for key, value in baseline.items():\n",
    "        if key not in compare_to:\n",
    "            result[key] = basline[key]\n",
    "            continue\n",
    "        diff = baseline[key] - compare_to[key]\n",
    "        if diff != 0:\n",
    "            result[key] = diff\n",
    "    return result\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c_1 = Counter((1, 1, 2))\n",
    "c_2 = Counter((1, 1, 3))\n",
    "print(c_1 - c_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = \"sgd+morph_lex-freeze+wemb-pretrained-300-reduced-lr\"\n",
    "baseline_errors = evaluate.all_errors(experiments[baseline][\"examples\"])\n",
    "for experiment_name in experiments:\n",
    "    if experiment_name == baseline:\n",
    "        continue\n",
    "    print(f\"{experiment_name}: First, in basline not in {experiment_name}, then in {experiment_name} not in basline.\")\n",
    "    pprint((evaluate.all_errors(experiments[baseline][\"examples\"]) - evaluate.all_errors(experiments[experiment_name][\"examples\"])).most_common(20))\n",
    "    pprint((evaluate.all_errors(experiments[experiment_name][\"examples\"]) - evaluate.all_errors(experiments[baseline][\"examples\"])).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitposconda0523c88e767045dc9cfcfe32838715d2",
   "display_name": "Python 3.7.6 64-bit ('pos': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}